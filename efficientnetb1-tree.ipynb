{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10828428,"sourceType":"datasetVersion","datasetId":6723755},{"sourceId":10866622,"sourceType":"datasetVersion","datasetId":6750782},{"sourceId":10866776,"sourceType":"datasetVersion","datasetId":6750878},{"sourceId":10871918,"sourceType":"datasetVersion","datasetId":6754651},{"sourceId":10881918,"sourceType":"datasetVersion","datasetId":6761683},{"sourceId":10881965,"sourceType":"datasetVersion","datasetId":6761722},{"sourceId":10882575,"sourceType":"datasetVersion","datasetId":6762185},{"sourceId":10883578,"sourceType":"datasetVersion","datasetId":6762943},{"sourceId":10884841,"sourceType":"datasetVersion","datasetId":6763820},{"sourceId":10885291,"sourceType":"datasetVersion","datasetId":6764133},{"sourceId":10885989,"sourceType":"datasetVersion","datasetId":6764533},{"sourceId":10886718,"sourceType":"datasetVersion","datasetId":6764957},{"sourceId":10887421,"sourceType":"datasetVersion","datasetId":6765392},{"sourceId":10888187,"sourceType":"datasetVersion","datasetId":6765870},{"sourceId":10888824,"sourceType":"datasetVersion","datasetId":6766352},{"sourceId":10889500,"sourceType":"datasetVersion","datasetId":6766869},{"sourceId":10890472,"sourceType":"datasetVersion","datasetId":6767609},{"sourceId":10891775,"sourceType":"datasetVersion","datasetId":6768576},{"sourceId":10893491,"sourceType":"datasetVersion","datasetId":6769809},{"sourceId":10894216,"sourceType":"datasetVersion","datasetId":6770294},{"sourceId":10894302,"sourceType":"datasetVersion","datasetId":6770345},{"sourceId":10895673,"sourceType":"datasetVersion","datasetId":6771153},{"sourceId":10896801,"sourceType":"datasetVersion","datasetId":6771883},{"sourceId":10969333,"sourceType":"datasetVersion","datasetId":6825203},{"sourceId":10969350,"sourceType":"datasetVersion","datasetId":6825217},{"sourceId":10969376,"sourceType":"datasetVersion","datasetId":6825238},{"sourceId":10973906,"sourceType":"datasetVersion","datasetId":6824099},{"sourceId":10974009,"sourceType":"datasetVersion","datasetId":6723640}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", tf.keras.mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) OPTIMIZED DATA LOADING USING `tf.data`\n# ====================================\ndef preprocess_image(image, label):\n    image = tf.image.resize(image, (224, 224))  # Resize to model input size\n    image = tf.keras.applications.efficientnet.preprocess_input(image)  # Normalize [-1, 1]\n    return image, label\n\ndef load_data(subset):\n    datagen = tf.keras.preprocessing.image_dataset_from_directory(\n        image_dir,\n        image_size=(224, 224),\n        batch_size=batch_size,\n        validation_split=0.2,\n        subset=subset,\n        seed=42,\n        label_mode='categorical'\n    )\n    return datagen.map(preprocess_image).cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n\ntrain_dataset = load_data(\"training\")\nval_dataset = load_data(\"validation\")\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_dataset, validation_data=val_dataset, epochs=1)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 64\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# , start_epoch=3\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# ====================================\n# 1) Basic Setup & Paths\n# ====================================\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"✅ Mixed precision enabled\")\n\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nweights_path = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"  # Uploaded weights\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\n\nbatch_size = 16  # ✅ Adjusted for better memory usage\ninput_shape = (224, 224, 3)\nepochs = 3\nlearning_rate = 0.0005\nfine_tune_layers = 50  # ✅ Unfreeze last 50 layers\n\n# ====================================\n# 2) Detect Classes\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(f\"📌 Detected {num_classes} classes\")\n\n# ====================================\n# 3) Optimized Data Pipeline\n# ====================================\ndef preprocess_image(image, label):\n    image = tf.image.resize(image, (224, 224))\n    image = tf.keras.applications.efficientnet.preprocess_input(image)\n    return image, label\n\ndef load_data(subset):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        image_dir,\n        image_size=(224, 224),\n        batch_size=batch_size,\n        validation_split=0.2,\n        subset=subset,\n        seed=42,\n        label_mode='categorical'\n    )\n    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    if subset == \"training\":\n        dataset = dataset.prefetch(tf.data.AUTOTUNE)  # ✅ No `cache()` to save RAM\n    else:\n        dataset = dataset.cache().prefetch(tf.data.AUTOTUNE)  # ✅ Cache only validation\n\n    return dataset\n\ntrain_dataset = load_data(\"training\")\nval_dataset = load_data(\"validation\")\n\n# ====================================\n# 4) Model Creation (Load Weights Manually)\n# ====================================\ndef create_model():\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=None,  # ✅ Avoids Kaggle download restrictions\n        input_shape=input_shape\n    )\n\n    # ✅ Load weights from uploaded file\n    if os.path.exists(weights_path):\n        base_model.load_weights(weights_path)\n        print(\"✅ Loaded EfficientNetB3 pretrained weights\")\n    else:\n        print(\"⚠️ Warning: Pretrained weights not found! Using random initialization.\")\n\n    base_model.trainable = True\n    for layer in base_model.layers[:-fine_tune_layers]:  \n        layer.trainable = False  # ✅ Freeze early layers\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.MaxPooling2D(pool_size=(2, 2)),  # ✅ Saves memory\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.4),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\n# ====================================\n# 5) Load or Create Model\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model with pretrained EfficientNetB3 weights\")\n\n# ====================================\n# 6) Training with Memory Fix\n# ====================================\nmodel.fit(train_dataset, validation_data=val_dataset, epochs=epochs)\nmodel.save(latest_model_path)\nprint(\"✅ Model saved!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\ntf.config.optimizer.set_jit(True)  # Enable XLA compilation for faster training\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\n# Reduce batch size to prevent RAM issues\nbatch_size = 16  # Reduced from 32 to avoid out-of-memory errors\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS (OPTIMIZED)\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\nAUTOTUNE = tf.data.AUTOTUNE  # Optimize data loading\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys()),\n    workers=2,  # Use 2 workers for faster data loading\n    use_multiprocessing=True  # Enable multiprocessing\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys()),\n    workers=2,\n    use_multiprocessing=True\n)\n\n# Prefetch data for better performance\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: train_generator,\n    output_signature=(\n        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32),\n    )\n).prefetch(buffer_size=AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_generator(\n    lambda: val_generator,\n    output_signature=(\n        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32),\n    )\n).prefetch(buffer_size=AUTOTUNE)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION (OPTIMIZED)\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 20  # Unfreeze last 20 layers (not 50)\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING (OPTIMIZED)\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_dataset, validation_data=val_dataset, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())  # Keep class order consistent\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,\n            workers=2,  # Multi-threaded data loading\n            use_multiprocessing=True  # Reduce RAM usage\n        )\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())  # Keep class order consistent\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\nsteps_per_epoch = len(train_generator)  # Ensures controlled training on large datasets\nvalidation_steps = len(val_generator)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,\n            steps_per_epoch=steps_per_epoch,\n            validation_steps=validation_steps\n        )\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.mixed_precision import set_global_policy\n\n# Enable mixed precision for GPU acceleration\ntry:\n    set_global_policy('mixed_float16')  # Remove this if using CPU\nexcept:\n    print(\"Mixed precision not available, using default float32.\")\n\n# Paths & parameters\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nbatch_size = 16  # Reduced to optimize RAM usage\ninput_shape = (300, 300, 3)  # Ensure resolution remains unchanged\nnum_classes = 27\n\n# Load EfficientNetB3 without top layers\nbase_model = EfficientNetB3(weights='/kaggle/input/efficientnetb3/efficientnetb3_notop.h5', \n                            include_top=False, input_shape=input_shape)\n\n# Freeze base model layers\nbase_model.trainable = False\n\n# Add custom classification head\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.4)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput = Dense(num_classes, activation='softmax', dtype='float32')(x)  # Ensure correct dtype\n\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Compile model\nmodel.compile(optimizer=Adam(learning_rate=0.0005),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Data augmentation & generators\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=False,  # Disable shuffle to reduce RAM usage\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n)\n\n# Training function to continue training across sessions\ndef train_model(model, epochs=2, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,  # Train 1 epoch per run to prevent crashes\n            verbose=1\n        )\n        model.save(f\"/kaggle/working/tree_classifier_epoch_{epoch}.h5\")  # Save after each epoch\n\n# Start training\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Adjust this to fit within Kaggle limits\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 16\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# , start_epoch=3\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\nimport matplotlib.pyplot as plt\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS (Kaggle)\n# ====================================\n# Update these paths according to your Kaggle environment:\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Dataset folder; each subfolder is a class.\nsave_dir = \"/kaggle/working\"                        # Model, history, and logs will be saved here.\nos.makedirs(save_dir, exist_ok=True)\n\n# We will save individual epoch models with a prefix and also keep a \"latest\" copy.\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# IMPORTANT: Set the path to your local downloaded weights file.\n# Upload your EfficientNetB3 weights file (e.g. \"efficientnetb3_notop.h5\") to the Kaggle working directory.\nweights_file = \"//kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload your EfficientNetB3 weights file to: \" + weights_file)\nelse:\n    print(\"Using local weights file:\", weights_file)\n\n# Basic training parameters\nbatch_size = 32         # You can try reducing this (e.g., to 16) if you need faster epochs.\ninput_shape = (224, 224, 3)\nbase_learning_rate = 0.0005\ninitial_epochs = 3       # Number of epochs per training session in the initial phase\nfine_tune_epochs = 5     # Number of epochs per fine-tuning session\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\n# Automatically detect classes from subfolders\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir)\n    if os.path.isdir(os.path.join(image_dir, d))\n)\n\n# If a class indices JSON exists, update it; otherwise, create a new mapping.\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        saved_class_indices = json.load(f)\n    # Add any new classes\n    for new_class in detected_classes:\n        if new_class not in saved_class_indices:\n            saved_class_indices[new_class] = len(saved_class_indices)\n    class_indices = saved_class_indices\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Updated class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\n# Use EfficientNet's preprocess_input to normalize inputs to [-1, 1]\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())  # Fixes the class order\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    # Build the base using EfficientNetB3 with local weights\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,  # Use local weights\n        input_shape=input_shape\n    )\n    if fine_tune:\n        base_model.trainable = True\n        # Unfreeze the last 30 layers; keep earlier layers frozen\n        fine_tune_at = len(base_model.layers) - 30\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = 1e-5  # Lower learning rate for fine-tuning\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        # Explicitly output float32 for compatibility with mixed precision\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) DEFINE CALLBACKS\n# ====================================\ncheckpoint_callback = ModelCheckpoint(\n    model_path,\n    save_weights_only=False,\n    save_best_only=False,  # Save every epoch\n    verbose=1\n)\nearly_stop = EarlyStopping(\n    patience=5,\n    restore_best_weights=True,\n    monitor='val_loss'\n)\nreduce_lr = ReduceLROnPlateau(\n    factor=0.5,\n    patience=2,\n    min_lr=1e-6,\n    verbose=1\n)\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\ncallbacks = [checkpoint_callback, early_stop, reduce_lr, tensorboard_callback]\n\n# ====================================\n# 8) TRAINING FUNCTION (WITH PER-EPOCH SAVING)\n# ====================================\ndef train_model(model, epochs=3, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        # Train for one epoch at a time\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=epoch + 1,\n            initial_epoch=epoch\n        )\n        # Save model after each epoch\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 9) MAIN TRAINING LOOP (INITIAL PHASE)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\nwhile True:\n    ans = input(\"Run another initial training session? (yes/no): \")\n    if ans.strip().lower() == \"yes\":\n        train_model(model, epochs=3)  # Run 3 epochs per session\n    else:\n        break\n\n# ====================================\n# 10) FINE-TUNING PHASE (Optional)\n# ====================================\nans = input(\"Proceed to fine-tuning phase? (yes/no): \")\nif ans.strip().lower() == \"yes\":\n    ft_model = create_model(fine_tune=True)\n    ft_model.load_weights(latest_model_path)\n    print(\"🔄 Starting fine-tuning with last 30 layers unfrozen.\")\n    train_model(ft_model, epochs=5)  # Fine-tune for 5 epochs per session\n    print(\"✅ Fine-tuning complete!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# Enable Mixed Precision & XLA for Speed Boost 🚀\nmixed_precision.set_global_policy('mixed_float16')\ntf.config.optimizer.set_jit(True)  # XLA Compilation\n\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\n# Hyperparameters (Optimized for Speed ⚡)\nbatch_size = 32  # Increased from 16 to 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 2  # Reduce epochs per session\nfine_tune_epochs = 3  # Fine-tune with fewer epochs\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\n\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA GENERATORS (Optimized)\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # EfficientNet built-in preprocessing\n    rotation_range=20,  # Reduced for speed\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.3),  # Reduced dropout for speed\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 6) CALLBACKS FOR FASTER TRAINING\n# ====================================\ncheckpoint_callback = ModelCheckpoint(\n    latest_model_path,  # Save latest model\n    save_weights_only=False,\n    save_best_only=False,  # Save every epoch\n    verbose=1\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=2,  # Stop early if no improvement\n    restore_best_weights=True\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=1,\n    verbose=1\n)\n\ntensorboard_callback = TensorBoard(log_dir=log_dir)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,\n            callbacks=[checkpoint_callback, reduce_lr, tensorboard_callback]\n        )\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Reduced epochs to save time\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb2/efficientnetb2_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB2 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB2(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this if dataset path is different\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = \"/kaggle/input/latest-nineteen/latest_model1.keras\"\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"  # Update the path if needed\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Adjust based on memory availability\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes images to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        # model.save(latest_model_path)\n        latest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\n        model.save(latest_model_path)  # ✅ Save in /kaggle/working/\n\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=1, start_epoch=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nprint(\"Classes detected:\", sorted(os.listdir(image_dir)))\n!pip install tensorflow keras numpy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Your dataset folder\nsave_dir = \"/kaggle/working\"  # Writable directory for saving checkpoints\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\n# For loading, use your uploaded model (in Kaggle input). Replace \"latest-nineteen\" with your actual folder.\nuploaded_model_path = \"/kaggle/input/latest-nineteenv3/latest_model1.keras\"\n# For saving, always use the working directory:\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"  # Update path if needed\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Adjust based on memory availability\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes images to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\n# Try to load the uploaded model first (from /kaggle/input)\nif os.path.exists(uploaded_model_path):\n    model = keras.models.load_model(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    # Note: latest_model_path is defined above for saving in /kaggle/working/\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE\n# ====================================\nprint(\"\\n=== Training Phase ===\")\n# For example, we resume training starting from epoch 2.\ntrain_model_func(model, epochs=3, start_epoch=4)\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# Before the session ends:\n#   1. Download the file at /kaggle/working/latest_model1.keras.\n# Next time:\n#   2. Upload the downloaded model to your Kaggle dataset (e.g., latest-nineteen).\n#   3. The above code will load the uploaded model from /kaggle/input/latest-nineteen/latest_model1.keras.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Dataset folder\nsave_dir = \"/kaggle/working\"  # Save model & logs\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-updatev1/latest_model1.keras\"  # Latest model from previous training\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"  # Ensure correct path\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Can adjust based on GPU memory\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Start with 10 epochs, can extend if needed\nfine_tune_learning_rate = 5e-6  # Lower LR to prevent overfitting\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes images to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 100  # Unfreeze last 100 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"❌ No previous model found. Train the model first before fine-tuning!\")\n    exit()\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1),\n        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) START FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=8)  # Start from epoch 7\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# Before the session ends:\n#   1. Download the file at /kaggle/working/latest_model1.keras.\n# Next time:\n#   2. Upload the downloaded model to your Kaggle dataset (e.g., latest-nineteen).\n#   3. The above code will load the uploaded model from /kaggle/input/latest-nineteen/latest_model1.keras.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-updatev2/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Adjust based on GPU memory\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Continue fine-tuning for 10+ more epochs\nfine_tune_learning_rate = 2e-6  # Reduce LR further to improve stability\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 150  # Unfreeze last 150 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"❌ No previous model found. Train the model first before fine-tuning!\")\n    exit()\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) CONTINUE FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase (Next Steps) ===\")\ntrain_model_func(fine_tune_model, epochs=2, start_epoch=11)  # Continue fine-tuning\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# Before the session ends:\n#   1. Download the file at /kaggle/working/latest_model1.keras.\n# Next time:\n#   2. Upload the downloaded model to your Kaggle dataset (e.g., latest-nineteen).\n#   3. The above code will load the uploaded model from /kaggle/input/latest-nineteen/latest_model1.keras.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-updatev15/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 64  # Try 64 if memory allows\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Continue fine-tuning for 10+ more epochs\nfine_tune_learning_rate = 2e-6  # Reduce LR further to improve stability\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n# datagen = ImageDataGenerator(\n#     preprocessing_function=preprocess_input,\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.3,\n#     horizontal_flip=True,\n#     brightness_range=[0.7, 1.3],\n#     fill_mode=\"nearest\",\n#     validation_split=0.2\n# )\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,  # Reduced from 40\n    width_shift_range=0.15,  # Reduced from 0.2\n    height_shift_range=0.15,  # Reduced from 0.2\n    shear_range=0.15,  # Reduced from 0.2\n    zoom_range=0.25,  # Reduced from 0.3\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Narrowed range\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 300  # Unfreeze last 180 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"❌ No previous model found. Train the model first before fine-tuning!\")\n    exit()\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) CONTINUE FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase (Next Steps) ===\")\ntrain_model_func(fine_tune_model, epochs=4, start_epoch=37)  # Continue fine-tuning\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_saved_model(\"your_model_directory\")\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable standard TFLite ops\n    tf.lite.OpsSet.SELECT_TF_OPS  # Enable Flex ops\n]\ntflite_model = converter.convert()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Get true labels and predictions\ntrue_labels = val_generator.classes\npred_probs = fine_tune_model.predict(val_generator)\npred_labels = np.argmax(pred_probs, axis=1)\n\n# Create confusion matrix\ncm = confusion_matrix(true_labels, pred_labels)\n\n# Plot\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=class_indices.keys(), yticklabels=class_indices.keys())\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\n\ndef get_gradcam(model, img_array, layer_name):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        class_idx = tf.argmax(predictions[0])\n        loss = predictions[:, class_idx]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n\n    for i in range(pooled_grads.shape[-1]):\n        conv_outputs[:, :, i] *= pooled_grads[i]\n\n    heatmap = np.mean(conv_outputs, axis=-1)\n    heatmap = np.maximum(heatmap, 0)\n    heatmap /= np.max(heatmap)\n\n    return heatmap\n\n# Test on a Tilia cordata image\nimg_path = \"/kaggle/input/trees-nineteen-dataset/Tilia_cordata/Tilia_cordata/Tilia cordata_1.png\"\nimg = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\n# Generate Grad-CAM\nheatmap = get_gradcam(fine_tune_model, img_array, \"top_conv\")  # Change \"top_conv\" to the last conv layer\n\n# Overlay on image\nheatmap = cv2.resize(heatmap, (224, 224))\nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\nsuperimposed_img = cv2.addWeighted(img_array[0].astype('uint8'), 0.6, heatmap, 0.4, 0)\nplt.imshow(superimposed_img)\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EfficientNetB3\nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-update/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB3 weights\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 64  # Can adjust if needed\ninput_shape = (300, 300, 3)  # EfficientNetB3's recommended input size\ninitial_learning_rate = 0.001\nfine_tune_learning_rate = 1e-6  # Lower for fine-tuning stability\nfine_tune_epochs = 10  # Adjust if needed\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreeze last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD MODEL OR TRAIN FROM SCRATCH\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    fine_tune_model = create_model(fine_tune=False)\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training complete!\")\n\n# ====================================\n# 8) START TRAINING PHASE\n# ====================================\nprint(\"\\n=== Training Phase ===\")\ntrain_model_func(fine_tune_model, epochs=2, start_epoch=1)  # Start training with 3 epochs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/convnext-tiny/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64  # Keep batch size same\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Continue fine-tuning\nfine_tune_learning_rate = 5e-6  # Start with 5e-6, can adjust later\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.convnext import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=20,  # Reduced rotation\n    width_shift_range=0.1,  # Reduced width shift\n    height_shift_range=0.1,  # Reduced height shift\n    shear_range=0.1,  # Reduced shear\n    zoom_range=0.2,  # Slightly reduced zoom\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Slightly reduced brightness variation\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.ConvNeXtTiny(\n        include_top=False,\n        weights='imagenet',\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 250  # Fine-tune last 250 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = 1e-4  # Higher LR for first training\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    fine_tune_model = create_model(fine_tune=False)\n    print(\"🚀 Training from scratch...\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) CONTINUE FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase (Next Steps) ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=1)  # Start fine-tuning\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/convnext-tiny/latest_model1.keras\"  # Update if resuming\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64  # Optimized for Kaggle\ninput_shape = (224, 224, 3)\ninitial_learning_rate = 5e-4  # Higher LR for base training\nfine_tune_learning_rate = 5e-6  # Lower LR for fine-tuning\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.convnext import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,  # Reduced from 40\n    width_shift_range=0.15,  # Reduced from 0.2\n    height_shift_range=0.15,\n    shear_range=0.15,  # Reduced from 0.2\n    zoom_range=0.2,  # Reduced from 0.3\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Less aggressive\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE CONVNEXT-TINY MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.ConvNeXtTiny(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 300  # Unfreezing last 300 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"🚀 Starting from scratch with ConvNeXt-Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (ConvNeXt-Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=1)\n\n# ====================================\n# 9) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase ===\")\nfine_tune_model = create_model(fine_tune=True)  # Reload with more trainable layers\nfine_tune_model.load_weights(latest_model_path)\ntrain_model_func(fine_tune_model, epochs=7, start_epoch=4)  # Fine-tune for 7 more epochs\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Zip the model file (replace with your filename)\nshutil.make_archive('model_checkpoint', 'zip', '/kaggle/working/')\n\n# Now download\nfrom IPython.display import FileLink\nFileLink(r'model_checkpoint.zip')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Create a ZIP file with only the model files\nshutil.make_archive('/kaggle/working/my_models', 'zip', '/kaggle/working', \n                     base_dir=None, verbose=True)\n\n# Generate a download link\nFileLink('/kaggle/working/my_models.zip')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.copy('/kaggle/working/latest_model1.keras', '/kaggle/input/latest_model1.keras')\nshutil.copy('/kaggle/working/model_epoch_2.keras', '/kaggle/input/model_epoch_2.keras')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nos.remove('/kaggle/working/model_checkpoint.zip')  # Delete the large ZIP\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\n# Define the zip file name\nzip_filename = \"/kaggle/working/my_models_fixed.zip\"\n\n# Create a zip file and add only the required models\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    zipf.write('/kaggle/working/latest_model1.keras', arcname='latest_model1.keras')\n    zipf.write('/kaggle/working/model_epoch_2.keras', arcname='model_epoch_2.keras')\n\n# Generate a download link\nfrom IPython.display import FileLink\nFileLink(zip_filename)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\nzip_filename = \"/kaggle/working/my_models_fixed_nineteen.zip\"\n\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    zipf.write('/kaggle/working/latest_model1.keras', arcname='latest_model1.keras')\n    zipf.write('/kaggle/working/model_epoch_2.keras', arcname='model_epoch_2.keras')\n\nprint(\"✅ Zip file created successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/working/my_models_fixed.zip /kaggle/working/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install kaggle\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/kaggle-dataset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meta_data = '''{\n  \"title\": \"My Saved Models\",\n  \"id\": \"your-username/my-saved-models\",\n  \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}'''\n\nwith open(\"/kaggle/working/kaggle-dataset/dataset-metadata.json\", \"w\") as f:\n    f.write(meta_data)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mv /kaggle/working/*.keras /kaggle/working/kaggle-dataset/\n!mv /kaggle/working/*.zip /kaggle/working/kaggle-dataset/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset/ --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!mv /kaggle/working/kaggle.json /root/.kaggle/\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!cp \"/kaggle/input/kaggle/kaggle (1).json\" /root/.kaggle/kaggle.json\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets list\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset/ --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset/ --private\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/my_models.zip /kaggle/working/kaggle-dataset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p ~/.kaggle\n!cp /kaggle/input/kaggle/kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle config view\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --user mohammedelhajsayed --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/kaggle-dataset/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat /kaggle/working/kaggle-dataset/dataset-metadata.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/kaggle-dataset/dataset-metadata.json\n{\n    \"title\": \"MyModelCheckpoints\",\n    \"id\": \"mohammedelhajsayed/mymodelcheckpoints\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:44:49.439436Z","iopub.execute_input":"2025-03-10T18:44:49.439730Z","iopub.status.idle":"2025-03-10T18:44:49.445998Z","shell.execute_reply.started":"2025-03-10T18:44:49.439706Z","shell.execute_reply":"2025-03-10T18:44:49.445249Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/kaggle-dataset/dataset-metadata.json\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/kaggle-dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:44:39.198009Z","iopub.execute_input":"2025-03-10T18:44:39.198296Z","iopub.status.idle":"2025-03-10T18:44:39.394173Z","shell.execute_reply.started":"2025-03-10T18:44:39.198274Z","shell.execute_reply":"2025-03-10T18:44:39.393052Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import shutil\n\nshutil.move(\"/kaggle/working/latest_model.keras\", \"/kaggle/working/kaggle-dataset/latest_model.keras\")\nshutil.move(\"/kaggle/working/model_epoch_8.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_8.keras\")\n# shutil.move(\"/kaggle/working/model_epoch_38.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_38.keras\")\n# shutil.move(\"/kaggle/working/model_epoch_39.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_39.keras\")\n# shutil.move(\"/kaggle/working/model_epoch_40.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_40.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:44:41.673507Z","iopub.execute_input":"2025-03-10T18:44:41.673807Z","iopub.status.idle":"2025-03-10T18:44:41.681060Z","shell.execute_reply.started":"2025-03-10T18:44:41.673783Z","shell.execute_reply":"2025-03-10T18:44:41.680368Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/kaggle-dataset/model_epoch_8.keras'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"metadata = '''{\n  \"title\": \"My Model Checkpoints\",\n  \"id\": \"your-kaggle-username/my-model-checkpoints\",\n  \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}'''\n\nwith open(\"/kaggle/working/kaggle-dataset/dataset-metadata.json\", \"w\") as f:\n    f.write(metadata)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:44:43.794310Z","iopub.execute_input":"2025-03-10T18:44:43.794593Z","iopub.status.idle":"2025-03-10T18:44:43.799272Z","shell.execute_reply.started":"2025-03-10T18:44:43.794571Z","shell.execute_reply":"2025-03-10T18:44:43.798583Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!cp /kaggle/input/kaggle/kaggle.json /root/.kaggle/kaggle.json\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:44:46.315242Z","iopub.execute_input":"2025-03-10T18:44:46.315515Z","iopub.status.idle":"2025-03-10T18:44:46.888929Z","shell.execute_reply.started":"2025-03-10T18:44:46.315494Z","shell.execute_reply":"2025-03-10T18:44:46.887966Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:44:52.502876Z","iopub.execute_input":"2025-03-10T18:44:52.503238Z","iopub.status.idle":"2025-03-10T18:44:57.134007Z","shell.execute_reply.started":"2025-03-10T18:44:52.503209Z","shell.execute_reply":"2025-03-10T18:44:57.133156Z"}},"outputs":[{"name":"stdout","text":"Starting upload for file model_epoch_8.keras\n100%|██████████████████████████████████████| 33.8M/33.8M [00:00<00:00, 52.5MB/s]\nUpload successful: model_epoch_8.keras (34MB)\nStarting upload for file latest_model.keras\n100%|██████████████████████████████████████| 33.8M/33.8M [00:00<00:00, 57.3MB/s]\nUpload successful: latest_model.keras (34MB)\nYour public Dataset is being created. Please check progress at https://www.kaggle.com/datasets/mohammedelhajsayed/mymodelcheckpoints\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/updatev5/latest_model1.keras\"  # Update this manually after re-upload\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")  # Won't be used after session ends\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64  # Optimized for Kaggle\ninput_shape = (224, 224, 3)\ninitial_learning_rate = 5e-4  # Higher LR for base training\nfine_tune_learning_rate = 5e-6  # Lower LR for fine-tuning\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.convnext import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,  # Reduced from 40\n    width_shift_range=0.15,  # Reduced from 0.2\n    height_shift_range=0.15,\n    shear_range=0.15,  # Reduced from 0.2\n    zoom_range=0.2,  # Reduced from 0.3\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Less aggressive\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE CONVNEXT-TINY MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.ConvNeXtTiny(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 300  # Unfreezing last 300 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)  # Load from uploaded path, NOT latest_model_path\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"🚀 Starting from scratch with ConvNeXt-Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE (3 EPOCHS) - YOU WILL COMMENT THIS OUT LATER\n# ====================================\nprint(\"\\n=== Initial Training Phase (ConvNeXt-Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=1)\n\n# ====================================\n# 9) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\n# 👉 AFTER RE-UPLOADING THE MODEL, COMMENT OUT THE INITIAL TRAINING SECTION ABOVE\n# 👉 THEN RUN ONLY THIS SECTION\n\nprint(\"\\n=== Fine-Tuning Phase ===\")\nfine_tune_model = create_model(fine_tune=True)  # Reload with more trainable layers\nfine_tune_model.load_weights(uploaded_model_path)  # Load from uploaded path, NOT latest_model_path\ntrain_model_func(fine_tune_model, epochs=4, start_epoch=20)  # Fine-tune for 7 more epochs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # EfficientNetB1 prefers 240x240\ninitial_learning_rate = 3e-4\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE EfficientNetB1 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB1!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB1) ===\")\ntrain_model_func(fine_tune_model, epochs=9, start_epoch=1)\n\n# ====================================\n# 8) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\n\n# print(\"\\n=== Fine-Tuning Phase ===\")\n# fine_tune_model = create_model(fine_tune=True)\n# fine_tune_model.load_weights(uploaded_model_path)\n# train_model_func(fine_tune_model, epochs=4, start_epoch=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T16:57:29.203757Z","iopub.execute_input":"2025-03-10T16:57:29.204334Z","iopub.status.idle":"2025-03-10T18:44:12.645295Z","shell.execute_reply.started":"2025-03-10T16:57:29.204298Z","shell.execute_reply":"2025-03-10T18:44:12.643714Z"}},"outputs":[{"name":"stdout","text":"Class indices: {'Azadirachta_indica': 0, 'Betula_pendula': 1, 'Camphora_officinarum': 2, 'Ceiba_pentandra': 3, 'Eucalyptus_globulus': 4, 'Ligustrum_lucidum': 5, 'Paulownia_tomentosa': 6, 'Pinus_halepensis': 7, 'Spathodea_campanulata': 8, 'Washingtonia_robusta': 9}\nFound 38989 images belonging to 10 classes.\nFound 9741 images belonging to 10 classes.\n🚀 Training from scratch with EfficientNetB1!\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n\u001b[1m27018416/27018416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n\n=== Initial Training Phase (EfficientNetB1) ===\n\n🔄 Training Epoch 1/9...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4069 - loss: 1.8993","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 1.04869, saving model to /kaggle/working/latest_model.keras\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 2s/step - accuracy: 0.4070 - loss: 1.8988 - val_accuracy: 0.6445 - val_loss: 1.0487 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_1.keras\n\n🔄 Training Epoch 2/9...\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957ms/step - accuracy: 0.5764 - loss: 1.2638\nEpoch 1: val_loss improved from 1.04869 to 0.96856, saving model to /kaggle/working/latest_model.keras\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 1s/step - accuracy: 0.5764 - loss: 1.2638 - val_accuracy: 0.6693 - val_loss: 0.9686 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_2.keras\n\n🔄 Training Epoch 3/9...\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964ms/step - accuracy: 0.6081 - loss: 1.1455\nEpoch 1: val_loss improved from 0.96856 to 0.92982, saving model to /kaggle/working/latest_model.keras\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 1s/step - accuracy: 0.6081 - loss: 1.1455 - val_accuracy: 0.6839 - val_loss: 0.9298 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_3.keras\n\n🔄 Training Epoch 4/9...\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959ms/step - accuracy: 0.6323 - loss: 1.0783\nEpoch 1: val_loss improved from 0.92982 to 0.88858, saving model to /kaggle/working/latest_model.keras\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 1s/step - accuracy: 0.6323 - loss: 1.0783 - val_accuracy: 0.6990 - val_loss: 0.8886 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_4.keras\n\n🔄 Training Epoch 5/9...\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955ms/step - accuracy: 0.6416 - loss: 1.0410\nEpoch 1: val_loss did not improve from 0.88858\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 1s/step - accuracy: 0.6416 - loss: 1.0410 - val_accuracy: 0.6997 - val_loss: 0.8908 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_5.keras\n\n🔄 Training Epoch 6/9...\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941ms/step - accuracy: 0.6565 - loss: 1.0003\nEpoch 1: val_loss improved from 0.88858 to 0.86915, saving model to /kaggle/working/latest_model.keras\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m731s\u001b[0m 1s/step - accuracy: 0.6565 - loss: 1.0003 - val_accuracy: 0.7057 - val_loss: 0.8692 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_6.keras\n\n🔄 Training Epoch 7/9...\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946ms/step - accuracy: 0.6723 - loss: 0.9591\nEpoch 1: val_loss improved from 0.86915 to 0.85703, saving model to /kaggle/working/latest_model.keras\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 1s/step - accuracy: 0.6723 - loss: 0.9591 - val_accuracy: 0.7139 - val_loss: 0.8570 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_7.keras\n\n🔄 Training Epoch 8/9...\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928ms/step - accuracy: 0.6678 - loss: 0.9739\nEpoch 1: val_loss improved from 0.85703 to 0.84852, saving model to /kaggle/working/latest_model.keras\n\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m715s\u001b[0m 1s/step - accuracy: 0.6678 - loss: 0.9738 - val_accuracy: 0.7127 - val_loss: 0.8485 - learning_rate: 3.0000e-04\n✅ Model saved: /kaggle/working/model_epoch_8.keras\n\n🔄 Training Epoch 9/9...\n\u001b[1m 10/610\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:03\u001b[0m 906ms/step - accuracy: 0.7038 - loss: 0.8894","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-02f60a5af093>\u001b[0m in \u001b[0;36m<cell line: 158>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;31m# ====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Initial Training Phase (EfficientNetB1) ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mtrain_model_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tune_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m# ====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-02f60a5af093>\u001b[0m in \u001b[0;36mtrain_model_func\u001b[0;34m(model, epochs, start_epoch)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mmodel_epoch_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_prefix}{epoch}.keras\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# import os\n# import json\n# import numpy as np\n# import tensorflow as tf\n# from tensorflow.keras.applications.efficientnet import preprocess_input\n# from tensorflow.keras.preprocessing import image\n# from tensorflow.keras.models import load_model\n# import matplotlib.pyplot as plt\n# from tkinter import Tk, filedialog\n\n# # ==============================\n# # 1) Load Model and Class Indices\n# # ==============================\n# model_path = \"/kaggle/input/flowers6testing/latest_model.keras\"  # Update as needed\n# class_indices_path = \"/kaggle/input/flowers6testing/class_indices (11).json\"\n\n# model = load_model(model_path)\n# with open(class_indices_path, 'r') as f:\n#     class_indices = json.load(f)\n# inv_class_indices = {v: k for k, v in class_indices.items()}\n\n# # ==============================\n# # 2) Select Image from PC\n# # ==============================\n# def select_image():\n#     root = Tk()\n#     root.withdraw()  # Hide the main window\n#     file_path = filedialog.askopenfilename(title=\"Select Image\", filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n#     return file_path\n\n# image_path = select_image()\n\n# # ==============================\n# # 3) Preprocess Image for Prediction\n# # ==============================\n# def preprocess_img(img_path):\n#     img = image.load_img(img_path, target_size=(240, 240))\n#     img_array = image.img_to_array(img)\n#     img_array = np.expand_dims(img_array, axis=0)\n#     return preprocess_input(img_array)\n\n# img_array = preprocess_img(image_path)\n\n# # ==============================\n# # 4) Prediction & Display\n# # ==============================\n# preds = model.predict(img_array)\n# pred_class = np.argmax(preds[0])\n# predicted_label = inv_class_indices[pred_class]\n\n# # Display Results\n# plt.imshow(image.load_img(image_path))\n# plt.axis('off')\n# plt.title(f\"Predicted: {predicted_label}\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nimport json\nimport os\n\n# Paths\nuploaded_model_path = \"/kaggle/input/flowers6testing/latest_model.keras\"  # Update if needed\nclass_indices_path = \"/kaggle/input/flowers6testing/class_indices (11).json\"   # Update if needed\nimage_path = \"/kaggle/input/cath-tset/cath5.png\"  # Change this after uploading your image\n\n# Load class indices\nwith open(class_indices_path, \"r\") as f:\n    class_indices = json.load(f)\nclass_labels = {v: k for k, v in class_indices.items()}\n\n# Load model\nmodel = tf.keras.models.load_model(uploaded_model_path)\n\n# Load and preprocess image\ndef preprocess_image(image_path, target_size=(240, 240)):\n    img = image.load_img(image_path, target_size=target_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    return preprocess_input(img_array)\n\n# Prediction\nimg_array = preprocess_image(image_path)\nprediction = model.predict(img_array)\npredicted_class = class_labels[np.argmax(prediction)]\n\nprint(f\"✅ Predicted Class: {predicted_class}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (256, 256, 3)  # Swin Transformer Tiny expects 256x256\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.swin_transformer import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE Swin Transformer Tiny MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.SwinTransformerTiny(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreezing last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with Swin Transformer Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (Swin Transformer Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n\n# ====================================\n# 8) FINE-TUNING PHASE (OPTIONAL)\n# ====================================\n\n# print(\"\\n=== Fine-Tuning Phase ===\")\n# fine_tune_model = create_model(fine_tune=True)\n# fine_tune_model.load_weights(uploaded_model_path)\n# train_model_func(fine_tune_model, epochs=4, start_epoch=4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install keras-cv\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install timm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras_cv\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  \nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  \ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # Swin Transformer prefers 224x224\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\ndatagen = ImageDataGenerator(\n    preprocessing_function=None,  # Swin Transformer does not require a built-in preprocessing function\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE SWIN TRANSFORMER MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras_cv.models.SwinTransformerTiny(\n        include_top=False,\n        input_shape=input_shape,\n        pretrained=True\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreezing last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with Swin Transformer!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (Swin Transformer Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:37:13.117538Z","iopub.execute_input":"2025-03-10T10:37:13.117824Z","iopub.status.idle":"2025-03-10T10:37:37.077109Z","shell.execute_reply.started":"2025-03-10T10:37:13.117803Z","shell.execute_reply":"2025-03-10T10:37:37.075769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport timm\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\n\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # Swin Transformer prefers 224x224\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\n\n\n# datagen = ImageDataGenerator(\n#     preprocessing_function=preprocess_input,\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.25,\n#     horizontal_flip=True,\n#     brightness_range=[0.7, 1.3],\n#     fill_mode=\"nearest\",\n#     validation_split=0.2\n# )\ndatagen = ImageDataGenerator(\n    preprocessing_function=lambda x: (x / 255.0 - 0.5) * 2,  # Normalize between -1 and 1\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE Swin Transformer Tiny MODEL\n# ====================================\n# def create_model(fine_tune=False):\n#     base_model = keras.applications.SwinTransformerTiny(\n#         include_top=False,\n#         weights=\"imagenet\",\n#         input_shape=input_shape\n#     )\n    \n#     if fine_tune:\n#         base_model.trainable = True\n#         fine_tune_at = len(base_model.layers) - 50  # Unfreezing last 50 layers\n#         for layer in base_model.layers[:fine_tune_at]:\n#             layer.trainable = False\n#         learning_rate = fine_tune_learning_rate\n#     else:\n#         base_model.trainable = False\n#         learning_rate = initial_learning_rate\n    \n#     model = keras.Sequential([\n#         keras.Input(shape=input_shape),\n#         base_model,\n#         layers.GlobalAveragePooling2D(),\n#         layers.BatchNormalization(),\n#         layers.Dense(512, activation='relu'),\n#         layers.Dropout(0.5),\n#         layers.Dense(num_classes, activation='softmax')\n#     ])\n    \n#     optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n#     model.compile(\n#         optimizer=optimizer,\n#         loss='categorical_crossentropy',\n#         metrics=['accuracy']\n#     )\n#     return model\ndef create_model(fine_tune=False):\n    base_model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=0)\n    base_model.trainable = fine_tune  # Freeze if fine_tune=False\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        layers.Lambda(lambda x: tf.image.resize(x, (224, 224))),  # Resize for Swin Transformer\n        base_model,\n        layers.GlobalAveragePooling2D(),\n\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=fine_tune_learning_rate if fine_tune else initial_learning_rate)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with Swin Transformer Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (Swin Transformer Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:44:47.626599Z","iopub.execute_input":"2025-03-10T10:44:47.626946Z","iopub.status.idle":"2025-03-10T10:45:03.719401Z","shell.execute_reply.started":"2025-03-10T10:44:47.626917Z","shell.execute_reply":"2025-03-10T10:45:03.717993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install timm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:40:26.359400Z","iopub.execute_input":"2025-03-10T10:40:26.359729Z","iopub.status.idle":"2025-03-10T10:40:29.677428Z","shell.execute_reply.started":"2025-03-10T10:40:26.359706Z","shell.execute_reply":"2025-03-10T10:40:29.676548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/flowers-nineteen19\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (300, 300, 3)  # EfficientNetB3 prefers 300x300\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE EfficientNetB3 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB3!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB3) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:48:24.152912Z","iopub.execute_input":"2025-03-10T10:48:24.153287Z","iopub.status.idle":"2025-03-10T10:48:27.577313Z","shell.execute_reply.started":"2025-03-10T10:48:24.153263Z","shell.execute_reply":"2025-03-10T10:48:27.576107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/flowers-nineteen19\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # EfficientNetB3 prefers 300x300\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) FIX DATASET STRUCTURE\n# ====================================\nfor class_name in os.listdir(image_dir):\n    class_path = os.path.join(image_dir, class_name)\n    if os.path.isdir(class_path):\n        subfolders = [f for f in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, f))]\n        for subfolder in subfolders:\n            subfolder_path = os.path.join(class_path, subfolder)\n            for file in os.listdir(subfolder_path):\n                src_path = os.path.join(subfolder_path, file)\n                dst_path = os.path.join(class_path, file)\n                shutil.move(src_path, dst_path)\n            os.rmdir(subfolder_path)\nprint(\"✅ Dataset structure fixed!\")\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE EfficientNetB3 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB3!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB3) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:54:43.160105Z","iopub.execute_input":"2025-03-10T10:54:43.160416Z","iopub.status.idle":"2025-03-10T10:54:55.245867Z","shell.execute_reply.started":"2025-03-10T10:54:43.160389Z","shell.execute_reply":"2025-03-10T10:54:55.244558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/flowers-nineteen19\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # EfficientNetB3 prefers 300x300\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE EfficientNetB3 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB3!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB3) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n\n# ====================================\n# 8) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\n\n# print(\"\\n=== Fine-Tuning Phase ===\")\n# fine_tune_model = create_model(fine_tune=True)\n# fine_tune_model.load_weights(uploaded_model_path)\n# train_model_func(fine_tune_model, epochs=4, start_epoch=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T11:04:58.280685Z","iopub.execute_input":"2025-03-10T11:04:58.281061Z","execution_failed":"2025-03-10T11:20:55.061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}