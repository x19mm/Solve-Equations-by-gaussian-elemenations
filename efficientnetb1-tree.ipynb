{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":10969376,"datasetId":6825238,"databundleVersionId":11345745},{"sourceType":"datasetVersion","sourceId":10969350,"datasetId":6825217,"databundleVersionId":11345718},{"sourceType":"datasetVersion","sourceId":10866776,"datasetId":6750878,"databundleVersionId":11231989},{"sourceType":"datasetVersion","sourceId":10866622,"datasetId":6750782,"databundleVersionId":11231805},{"sourceType":"datasetVersion","sourceId":10828428,"datasetId":6723755,"databundleVersionId":11189613},{"sourceType":"datasetVersion","sourceId":10890472,"datasetId":6767609,"databundleVersionId":11258291},{"sourceType":"datasetVersion","sourceId":10891775,"datasetId":6768576,"databundleVersionId":11259736},{"sourceType":"datasetVersion","sourceId":10893491,"datasetId":6769809,"databundleVersionId":11261665},{"sourceType":"datasetVersion","sourceId":10894216,"datasetId":6770294,"databundleVersionId":11262470},{"sourceType":"datasetVersion","sourceId":10894302,"datasetId":6770345,"databundleVersionId":11262560},{"sourceType":"datasetVersion","sourceId":10895673,"datasetId":6771153,"databundleVersionId":11264053},{"sourceType":"datasetVersion","sourceId":10896801,"datasetId":6771883,"databundleVersionId":11265293},{"sourceType":"datasetVersion","sourceId":10885291,"datasetId":6764133,"databundleVersionId":11252588},{"sourceType":"datasetVersion","sourceId":10885989,"datasetId":6764533,"databundleVersionId":11253356},{"sourceType":"datasetVersion","sourceId":10886718,"datasetId":6764957,"databundleVersionId":11254146},{"sourceType":"datasetVersion","sourceId":10887421,"datasetId":6765392,"databundleVersionId":11254917},{"sourceType":"datasetVersion","sourceId":10888187,"datasetId":6765870,"databundleVersionId":11255750},{"sourceType":"datasetVersion","sourceId":10888824,"datasetId":6766352,"databundleVersionId":11256457},{"sourceType":"datasetVersion","sourceId":10889500,"datasetId":6766869,"databundleVersionId":11257227},{"sourceType":"datasetVersion","sourceId":10884841,"datasetId":6763820,"databundleVersionId":11252065},{"sourceType":"datasetVersion","sourceId":10973906,"datasetId":6824099,"databundleVersionId":11350782},{"sourceType":"datasetVersion","sourceId":10969333,"datasetId":6825203,"databundleVersionId":11345696},{"sourceType":"datasetVersion","sourceId":10881918,"datasetId":6761683,"databundleVersionId":11248802},{"sourceType":"datasetVersion","sourceId":10871918,"datasetId":6754651,"databundleVersionId":11237676},{"sourceType":"datasetVersion","sourceId":10881965,"datasetId":6761722,"databundleVersionId":11248857},{"sourceType":"datasetVersion","sourceId":10882575,"datasetId":6762185,"databundleVersionId":11249529},{"sourceType":"datasetVersion","sourceId":10883578,"datasetId":6762943,"databundleVersionId":11250640},{"sourceType":"datasetVersion","sourceId":10974009,"datasetId":6723640,"databundleVersionId":11350904}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", tf.keras.mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) OPTIMIZED DATA LOADING USING `tf.data`\n# ====================================\ndef preprocess_image(image, label):\n    image = tf.image.resize(image, (224, 224))  # Resize to model input size\n    image = tf.keras.applications.efficientnet.preprocess_input(image)  # Normalize [-1, 1]\n    return image, label\n\ndef load_data(subset):\n    datagen = tf.keras.preprocessing.image_dataset_from_directory(\n        image_dir,\n        image_size=(224, 224),\n        batch_size=batch_size,\n        validation_split=0.2,\n        subset=subset,\n        seed=42,\n        label_mode='categorical'\n    )\n    return datagen.map(preprocess_image).cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n\ntrain_dataset = load_data(\"training\")\nval_dataset = load_data(\"validation\")\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_dataset, validation_data=val_dataset, epochs=1)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 64\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# , start_epoch=3\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# ====================================\n# 1) Basic Setup & Paths\n# ====================================\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"✅ Mixed precision enabled\")\n\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nweights_path = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"  # Uploaded weights\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\n\nbatch_size = 16  # ✅ Adjusted for better memory usage\ninput_shape = (224, 224, 3)\nepochs = 3\nlearning_rate = 0.0005\nfine_tune_layers = 50  # ✅ Unfreeze last 50 layers\n\n# ====================================\n# 2) Detect Classes\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(f\"📌 Detected {num_classes} classes\")\n\n# ====================================\n# 3) Optimized Data Pipeline\n# ====================================\ndef preprocess_image(image, label):\n    image = tf.image.resize(image, (224, 224))\n    image = tf.keras.applications.efficientnet.preprocess_input(image)\n    return image, label\n\ndef load_data(subset):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        image_dir,\n        image_size=(224, 224),\n        batch_size=batch_size,\n        validation_split=0.2,\n        subset=subset,\n        seed=42,\n        label_mode='categorical'\n    )\n    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    if subset == \"training\":\n        dataset = dataset.prefetch(tf.data.AUTOTUNE)  # ✅ No `cache()` to save RAM\n    else:\n        dataset = dataset.cache().prefetch(tf.data.AUTOTUNE)  # ✅ Cache only validation\n\n    return dataset\n\ntrain_dataset = load_data(\"training\")\nval_dataset = load_data(\"validation\")\n\n# ====================================\n# 4) Model Creation (Load Weights Manually)\n# ====================================\ndef create_model():\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=None,  # ✅ Avoids Kaggle download restrictions\n        input_shape=input_shape\n    )\n\n    # ✅ Load weights from uploaded file\n    if os.path.exists(weights_path):\n        base_model.load_weights(weights_path)\n        print(\"✅ Loaded EfficientNetB3 pretrained weights\")\n    else:\n        print(\"⚠️ Warning: Pretrained weights not found! Using random initialization.\")\n\n    base_model.trainable = True\n    for layer in base_model.layers[:-fine_tune_layers]:  \n        layer.trainable = False  # ✅ Freeze early layers\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.MaxPooling2D(pool_size=(2, 2)),  # ✅ Saves memory\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.4),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\n# ====================================\n# 5) Load or Create Model\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model with pretrained EfficientNetB3 weights\")\n\n# ====================================\n# 6) Training with Memory Fix\n# ====================================\nmodel.fit(train_dataset, validation_data=val_dataset, epochs=epochs)\nmodel.save(latest_model_path)\nprint(\"✅ Model saved!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\ntf.config.optimizer.set_jit(True)  # Enable XLA compilation for faster training\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\n# Reduce batch size to prevent RAM issues\nbatch_size = 16  # Reduced from 32 to avoid out-of-memory errors\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS (OPTIMIZED)\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\nAUTOTUNE = tf.data.AUTOTUNE  # Optimize data loading\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys()),\n    workers=2,  # Use 2 workers for faster data loading\n    use_multiprocessing=True  # Enable multiprocessing\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys()),\n    workers=2,\n    use_multiprocessing=True\n)\n\n# Prefetch data for better performance\ntrain_dataset = tf.data.Dataset.from_generator(\n    lambda: train_generator,\n    output_signature=(\n        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32),\n    )\n).prefetch(buffer_size=AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_generator(\n    lambda: val_generator,\n    output_signature=(\n        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32),\n    )\n).prefetch(buffer_size=AUTOTUNE)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION (OPTIMIZED)\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 20  # Unfreeze last 20 layers (not 50)\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING (OPTIMIZED)\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_dataset, validation_data=val_dataset, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())  # Keep class order consistent\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,\n            workers=2,  # Multi-threaded data loading\n            use_multiprocessing=True  # Reduce RAM usage\n        )\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())  # Keep class order consistent\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\nsteps_per_epoch = len(train_generator)  # Ensures controlled training on large datasets\nvalidation_steps = len(val_generator)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,\n            steps_per_epoch=steps_per_epoch,\n            validation_steps=validation_steps\n        )\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.mixed_precision import set_global_policy\n\n# Enable mixed precision for GPU acceleration\ntry:\n    set_global_policy('mixed_float16')  # Remove this if using CPU\nexcept:\n    print(\"Mixed precision not available, using default float32.\")\n\n# Paths & parameters\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nbatch_size = 16  # Reduced to optimize RAM usage\ninput_shape = (300, 300, 3)  # Ensure resolution remains unchanged\nnum_classes = 27\n\n# Load EfficientNetB3 without top layers\nbase_model = EfficientNetB3(weights='/kaggle/input/efficientnetb3/efficientnetb3_notop.h5', \n                            include_top=False, input_shape=input_shape)\n\n# Freeze base model layers\nbase_model.trainable = False\n\n# Add custom classification head\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.4)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput = Dense(num_classes, activation='softmax', dtype='float32')(x)  # Ensure correct dtype\n\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Compile model\nmodel.compile(optimizer=Adam(learning_rate=0.0005),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Data augmentation & generators\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=False,  # Disable shuffle to reduce RAM usage\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n)\n\n# Training function to continue training across sessions\ndef train_model(model, epochs=2, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,  # Train 1 epoch per run to prevent crashes\n            verbose=1\n        )\n        model.save(f\"/kaggle/working/tree_classifier_epoch_{epoch}.h5\")  # Save after each epoch\n\n# Start training\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Adjust this to fit within Kaggle limits\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 16\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# , start_epoch=3\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\nimport matplotlib.pyplot as plt\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS (Kaggle)\n# ====================================\n# Update these paths according to your Kaggle environment:\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Dataset folder; each subfolder is a class.\nsave_dir = \"/kaggle/working\"                        # Model, history, and logs will be saved here.\nos.makedirs(save_dir, exist_ok=True)\n\n# We will save individual epoch models with a prefix and also keep a \"latest\" copy.\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# IMPORTANT: Set the path to your local downloaded weights file.\n# Upload your EfficientNetB3 weights file (e.g. \"efficientnetb3_notop.h5\") to the Kaggle working directory.\nweights_file = \"//kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload your EfficientNetB3 weights file to: \" + weights_file)\nelse:\n    print(\"Using local weights file:\", weights_file)\n\n# Basic training parameters\nbatch_size = 32         # You can try reducing this (e.g., to 16) if you need faster epochs.\ninput_shape = (224, 224, 3)\nbase_learning_rate = 0.0005\ninitial_epochs = 3       # Number of epochs per training session in the initial phase\nfine_tune_epochs = 5     # Number of epochs per fine-tuning session\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\n# Automatically detect classes from subfolders\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir)\n    if os.path.isdir(os.path.join(image_dir, d))\n)\n\n# If a class indices JSON exists, update it; otherwise, create a new mapping.\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        saved_class_indices = json.load(f)\n    # Add any new classes\n    for new_class in detected_classes:\n        if new_class not in saved_class_indices:\n            saved_class_indices[new_class] = len(saved_class_indices)\n    class_indices = saved_class_indices\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Updated class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\n# Use EfficientNet's preprocess_input to normalize inputs to [-1, 1]\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())  # Fixes the class order\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    # Build the base using EfficientNetB3 with local weights\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,  # Use local weights\n        input_shape=input_shape\n    )\n    if fine_tune:\n        base_model.trainable = True\n        # Unfreeze the last 30 layers; keep earlier layers frozen\n        fine_tune_at = len(base_model.layers) - 30\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = 1e-5  # Lower learning rate for fine-tuning\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        # Explicitly output float32 for compatibility with mixed precision\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) DEFINE CALLBACKS\n# ====================================\ncheckpoint_callback = ModelCheckpoint(\n    model_path,\n    save_weights_only=False,\n    save_best_only=False,  # Save every epoch\n    verbose=1\n)\nearly_stop = EarlyStopping(\n    patience=5,\n    restore_best_weights=True,\n    monitor='val_loss'\n)\nreduce_lr = ReduceLROnPlateau(\n    factor=0.5,\n    patience=2,\n    min_lr=1e-6,\n    verbose=1\n)\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\ncallbacks = [checkpoint_callback, early_stop, reduce_lr, tensorboard_callback]\n\n# ====================================\n# 8) TRAINING FUNCTION (WITH PER-EPOCH SAVING)\n# ====================================\ndef train_model(model, epochs=3, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        # Train for one epoch at a time\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=epoch + 1,\n            initial_epoch=epoch\n        )\n        # Save model after each epoch\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 9) MAIN TRAINING LOOP (INITIAL PHASE)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\nwhile True:\n    ans = input(\"Run another initial training session? (yes/no): \")\n    if ans.strip().lower() == \"yes\":\n        train_model(model, epochs=3)  # Run 3 epochs per session\n    else:\n        break\n\n# ====================================\n# 10) FINE-TUNING PHASE (Optional)\n# ====================================\nans = input(\"Proceed to fine-tuning phase? (yes/no): \")\nif ans.strip().lower() == \"yes\":\n    ft_model = create_model(fine_tune=True)\n    ft_model.load_weights(latest_model_path)\n    print(\"🔄 Starting fine-tuning with last 30 layers unfrozen.\")\n    train_model(ft_model, epochs=5)  # Fine-tune for 5 epochs per session\n    print(\"✅ Fine-tuning complete!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# Enable Mixed Precision & XLA for Speed Boost 🚀\nmixed_precision.set_global_policy('mixed_float16')\ntf.config.optimizer.set_jit(True)  # XLA Compilation\n\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\n# Hyperparameters (Optimized for Speed ⚡)\nbatch_size = 32  # Increased from 16 to 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 2  # Reduce epochs per session\nfine_tune_epochs = 3  # Fine-tune with fewer epochs\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\n\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA GENERATORS (Optimized)\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # EfficientNet built-in preprocessing\n    rotation_range=20,  # Reduced for speed\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.3),  # Reduced dropout for speed\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 6) CALLBACKS FOR FASTER TRAINING\n# ====================================\ncheckpoint_callback = ModelCheckpoint(\n    latest_model_path,  # Save latest model\n    save_weights_only=False,\n    save_best_only=False,  # Save every epoch\n    verbose=1\n)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=2,  # Stop early if no improvement\n    restore_best_weights=True\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=1,\n    verbose=1\n)\n\ntensorboard_callback = TensorBoard(log_dir=log_dir)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(\n            train_generator,\n            validation_data=val_generator,\n            epochs=1,\n            callbacks=[checkpoint_callback, reduce_lr, tensorboard_callback]\n        )\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Reduced epochs to save time\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nweights_file = \"/kaggle/input/efficientnetb2/efficientnetb2_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB2 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB2(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=2)  # Run only 2 epochs per Kaggle session\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this if dataset path is different\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nlatest_model_path = \"/kaggle/input/latest-nineteen/latest_model1.keras\"\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"  # Update the path if needed\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Adjust based on memory availability\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes images to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\nif os.path.exists(latest_model_path):\n    model = keras.models.load_model(latest_model_path)\n    print(\"✅ Loaded latest model from disk.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model(model, epochs, start_epoch=1):\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        # model.save(latest_model_path)\n        latest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\n        model.save(latest_model_path)  # ✅ Save in /kaggle/working/\n\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING (SAVES EVERY EPOCH)\n# ====================================\nprint(\"\\n=== Initial Training Phase ===\")\ntrain_model(model, epochs=1, start_epoch=2)  # Run only 2 epochs per Kaggle session\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# 1. Upload the latest saved model (e.g., model_epoch_2.keras) to Kaggle input.\n# 2. Update 'latest_model_path' to point to the uploaded model.\n# 3. Restart training from the next epoch.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nprint(\"Classes detected:\", sorted(os.listdir(image_dir)))\n!pip install tensorflow keras numpy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Your dataset folder\nsave_dir = \"/kaggle/working\"  # Writable directory for saving checkpoints\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\n# For loading, use your uploaded model (in Kaggle input). Replace \"latest-nineteen\" with your actual folder.\nuploaded_model_path = \"/kaggle/input/latest-nineteenv3/latest_model1.keras\"\n# For saving, always use the working directory:\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"  # Update path if needed\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Adjust based on memory availability\ninput_shape = (224, 224, 3)\ninitial_epochs = 3\nfine_tune_epochs = 5\nbase_learning_rate = 0.0005\nfine_tune_learning_rate = 1e-6\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes images to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL CREATION FUNCTION\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD OR CREATE MODEL\n# ====================================\n# Try to load the uploaded model first (from /kaggle/input)\nif os.path.exists(uploaded_model_path):\n    model = keras.models.load_model(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file.\")\nelse:\n    model = create_model()\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH PER-EPOCH SAVING\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    # Note: latest_model_path is defined above for saving in /kaggle/working/\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n        \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE\n# ====================================\nprint(\"\\n=== Training Phase ===\")\n# For example, we resume training starting from epoch 2.\ntrain_model_func(model, epochs=3, start_epoch=4)\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# Before the session ends:\n#   1. Download the file at /kaggle/working/latest_model1.keras.\n# Next time:\n#   2. Upload the downloaded model to your Kaggle dataset (e.g., latest-nineteen).\n#   3. The above code will load the uploaded model from /kaggle/input/latest-nineteen/latest_model1.keras.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Dataset folder\nsave_dir = \"/kaggle/working\"  # Save model & logs\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-updatev1/latest_model1.keras\"  # Latest model from previous training\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"  # Ensure correct path\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Can adjust based on GPU memory\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Start with 10 epochs, can extend if needed\nfine_tune_learning_rate = 5e-6  # Lower LR to prevent overfitting\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,  # Normalizes images to [-1, 1]\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 100  # Unfreeze last 100 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"❌ No previous model found. Train the model first before fine-tuning!\")\n    exit()\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1),\n        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) START FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=8)  # Start from epoch 7\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# Before the session ends:\n#   1. Download the file at /kaggle/working/latest_model1.keras.\n# Next time:\n#   2. Upload the downloaded model to your Kaggle dataset (e.g., latest-nineteen).\n#   3. The above code will load the uploaded model from /kaggle/input/latest-nineteen/latest_model1.keras.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-updatev2/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 32  # Adjust based on GPU memory\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Continue fine-tuning for 10+ more epochs\nfine_tune_learning_rate = 2e-6  # Reduce LR further to improve stability\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 150  # Unfreeze last 150 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"❌ No previous model found. Train the model first before fine-tuning!\")\n    exit()\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) CONTINUE FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase (Next Steps) ===\")\ntrain_model_func(fine_tune_model, epochs=2, start_epoch=11)  # Continue fine-tuning\n\n# ====================================\n# 9) HOW TO RESUME TRAINING NEXT TIME\n# ====================================\n# Before the session ends:\n#   1. Download the file at /kaggle/working/latest_model1.keras.\n# Next time:\n#   2. Upload the downloaded model to your Kaggle dataset (e.g., latest-nineteen).\n#   3. The above code will load the uploaded model from /kaggle/input/latest-nineteen/latest_model1.keras.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-updatev15/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB1 weights\nweights_file = \"/kaggle/input/efficientnetb1-notop/efficientnetb1_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB1 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 64  # Try 64 if memory allows\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Continue fine-tuning for 10+ more epochs\nfine_tune_learning_rate = 2e-6  # Reduce LR further to improve stability\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n# datagen = ImageDataGenerator(\n#     preprocessing_function=preprocess_input,\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.3,\n#     horizontal_flip=True,\n#     brightness_range=[0.7, 1.3],\n#     fill_mode=\"nearest\",\n#     validation_split=0.2\n# )\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,  # Reduced from 40\n    width_shift_range=0.15,  # Reduced from 0.2\n    height_shift_range=0.15,  # Reduced from 0.2\n    shear_range=0.15,  # Reduced from 0.2\n    zoom_range=0.25,  # Reduced from 0.3\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Narrowed range\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 300  # Unfreeze last 180 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = base_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"❌ No previous model found. Train the model first before fine-tuning!\")\n    exit()\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) CONTINUE FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase (Next Steps) ===\")\ntrain_model_func(fine_tune_model, epochs=4, start_epoch=37)  # Continue fine-tuning\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_saved_model(\"your_model_directory\")\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable standard TFLite ops\n    tf.lite.OpsSet.SELECT_TF_OPS  # Enable Flex ops\n]\ntflite_model = converter.convert()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Get true labels and predictions\ntrue_labels = val_generator.classes\npred_probs = fine_tune_model.predict(val_generator)\npred_labels = np.argmax(pred_probs, axis=1)\n\n# Create confusion matrix\ncm = confusion_matrix(true_labels, pred_labels)\n\n# Plot\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=class_indices.keys(), yticklabels=class_indices.keys())\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\n\ndef get_gradcam(model, img_array, layer_name):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        class_idx = tf.argmax(predictions[0])\n        loss = predictions[:, class_idx]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n\n    for i in range(pooled_grads.shape[-1]):\n        conv_outputs[:, :, i] *= pooled_grads[i]\n\n    heatmap = np.mean(conv_outputs, axis=-1)\n    heatmap = np.maximum(heatmap, 0)\n    heatmap /= np.max(heatmap)\n\n    return heatmap\n\n# Test on a Tilia cordata image\nimg_path = \"/kaggle/input/trees-nineteen-dataset/Tilia_cordata/Tilia_cordata/Tilia cordata_1.png\"\nimg = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\n# Generate Grad-CAM\nheatmap = get_gradcam(fine_tune_model, img_array, \"top_conv\")  # Change \"top_conv\" to the last conv layer\n\n# Overlay on image\nheatmap = cv2.resize(heatmap, (224, 224))\nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\nsuperimposed_img = cv2.addWeighted(img_array[0].astype('uint8'), 0.6, heatmap, 0.4, 0)\nplt.imshow(superimposed_img)\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EfficientNetB3\nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/fine-update/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\n# ✅ Use locally uploaded EfficientNetB3 weights\nweights_file = \"/kaggle/input/efficientnetb3/efficientnetb3_notop.h5\"\nif not os.path.exists(weights_file):\n    raise FileNotFoundError(\"Weights file not found! Please upload EfficientNetB3 weights.\")\nelse:\n    print(\"Using local weights file:\", weights_file)\n\nbatch_size = 64  # Can adjust if needed\ninput_shape = (300, 300, 3)  # EfficientNetB3's recommended input size\ninitial_learning_rate = 0.001\nfine_tune_learning_rate = 1e-6  # Lower for fine-tuning stability\nfine_tune_epochs = 10  # Adjust if needed\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=weights_file,\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreeze last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD MODEL OR TRAIN FROM SCRATCH\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    fine_tune_model = create_model(fine_tune=False)\n    print(\"🚀 Created new model from scratch.\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)  # Save latest model in /kaggle/working/\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training complete!\")\n\n# ====================================\n# 8) START TRAINING PHASE\n# ====================================\nprint(\"\\n=== Training Phase ===\")\ntrain_model_func(fine_tune_model, epochs=2, start_epoch=1)  # Start training with 3 epochs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/convnext-tiny/latest_model1.keras\"\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64  # Keep batch size same\ninput_shape = (224, 224, 3)\nfine_tune_epochs = 10  # Continue fine-tuning\nfine_tune_learning_rate = 5e-6  # Start with 5e-6, can adjust later\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(\n    d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))\n)\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) SET UP DATA GENERATORS\n# ====================================\nfrom tensorflow.keras.applications.convnext import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=20,  # Reduced rotation\n    width_shift_range=0.1,  # Reduced width shift\n    height_shift_range=0.1,  # Reduced height shift\n    shear_range=0.1,  # Reduced shear\n    zoom_range=0.2,  # Slightly reduced zoom\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Slightly reduced brightness variation\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE FINE-TUNING MODEL\n# ====================================\ndef create_model(fine_tune=True):\n    base_model = keras.applications.ConvNeXtTiny(\n        include_top=False,\n        weights='imagenet',\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 250  # Fine-tune last 250 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = 1e-4  # Higher LR for first training\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL & START FINE-TUNING\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    fine_tune_model = create_model(fine_tune=False)\n    print(\"🚀 Training from scratch...\")\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Fine-Tuning Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    print(\"✅ Fine-tuning complete!\")\n\n# ====================================\n# 8) CONTINUE FINE-TUNING PHASE\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase (Next Steps) ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=1)  # Start fine-tuning\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/convnext-tiny/latest_model1.keras\"  # Update if resuming\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64  # Optimized for Kaggle\ninput_shape = (224, 224, 3)\ninitial_learning_rate = 5e-4  # Higher LR for base training\nfine_tune_learning_rate = 5e-6  # Lower LR for fine-tuning\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.convnext import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,  # Reduced from 40\n    width_shift_range=0.15,  # Reduced from 0.2\n    height_shift_range=0.15,\n    shear_range=0.15,  # Reduced from 0.2\n    zoom_range=0.2,  # Reduced from 0.3\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Less aggressive\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE CONVNEXT-TINY MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.ConvNeXtTiny(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 300  # Unfreezing last 300 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"🚀 Starting from scratch with ConvNeXt-Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (ConvNeXt-Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=1)\n\n# ====================================\n# 9) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\nprint(\"\\n=== Fine-Tuning Phase ===\")\nfine_tune_model = create_model(fine_tune=True)  # Reload with more trainable layers\nfine_tune_model.load_weights(latest_model_path)\ntrain_model_func(fine_tune_model, epochs=7, start_epoch=4)  # Fine-tune for 7 more epochs\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Zip the model file (replace with your filename)\nshutil.make_archive('model_checkpoint', 'zip', '/kaggle/working/')\n\n# Now download\nfrom IPython.display import FileLink\nFileLink(r'model_checkpoint.zip')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Create a ZIP file with only the model files\nshutil.make_archive('/kaggle/working/my_models', 'zip', '/kaggle/working', \n                     base_dir=None, verbose=True)\n\n# Generate a download link\nFileLink('/kaggle/working/my_models.zip')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.copy('/kaggle/working/latest_model1.keras', '/kaggle/input/latest_model1.keras')\nshutil.copy('/kaggle/working/model_epoch_2.keras', '/kaggle/input/model_epoch_2.keras')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nos.remove('/kaggle/working/model_checkpoint.zip')  # Delete the large ZIP\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\n# Define the zip file name\nzip_filename = \"/kaggle/working/my_models_fixed.zip\"\n\n# Create a zip file and add only the required models\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    zipf.write('/kaggle/working/latest_model1.keras', arcname='latest_model1.keras')\n    zipf.write('/kaggle/working/model_epoch_2.keras', arcname='model_epoch_2.keras')\n\n# Generate a download link\nfrom IPython.display import FileLink\nFileLink(zip_filename)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh /kaggle/working/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\nzip_filename = \"/kaggle/working/my_models_fixed_nineteen.zip\"\n\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    zipf.write('/kaggle/working/latest_model1.keras', arcname='latest_model1.keras')\n    zipf.write('/kaggle/working/model_epoch_2.keras', arcname='model_epoch_2.keras')\n\nprint(\"✅ Zip file created successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/working/my_models_fixed.zip /kaggle/working/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install kaggle\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/kaggle-dataset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meta_data = '''{\n  \"title\": \"My Saved Models\",\n  \"id\": \"your-username/my-saved-models\",\n  \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}'''\n\nwith open(\"/kaggle/working/kaggle-dataset/dataset-metadata.json\", \"w\") as f:\n    f.write(meta_data)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mv /kaggle/working/*.keras /kaggle/working/kaggle-dataset/\n!mv /kaggle/working/*.zip /kaggle/working/kaggle-dataset/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset/ --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!mv /kaggle/working/kaggle.json /root/.kaggle/\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!cp \"/kaggle/input/kaggle/kaggle (1).json\" /root/.kaggle/kaggle.json\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets list\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset/ --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset/ --private\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/my_models.zip /kaggle/working/kaggle-dataset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p ~/.kaggle\n!cp /kaggle/input/kaggle/kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle config view\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --user mohammedelhajsayed --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/kaggle-dataset/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat /kaggle/working/kaggle-dataset/dataset-metadata.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/kaggle-dataset/dataset-metadata.json\n{\n    \"title\": \"MyModelCheckpoints\",\n    \"id\": \"mohammedelhajsayed/mymodelcheckpoints\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /kaggle/working/kaggle-dataset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.move(\"/kaggle/working/latest_model.keras\", \"/kaggle/working/kaggle-dataset/latest_model.keras\")\nshutil.move(\"/kaggle/working/model_epoch_20.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_20.keras\")\n# shutil.move(\"/kaggle/working/model_epoch_38.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_38.keras\")\n# shutil.move(\"/kaggle/working/model_epoch_39.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_39.keras\")\n# shutil.move(\"/kaggle/working/model_epoch_40.keras\", \"/kaggle/working/kaggle-dataset/model_epoch_40.keras\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata = '''{\n  \"title\": \"My Model Checkpoints\",\n  \"id\": \"your-kaggle-username/my-model-checkpoints\",\n  \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}'''\n\nwith open(\"/kaggle/working/kaggle-dataset/dataset-metadata.json\", \"w\") as f:\n    f.write(metadata)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!cp /kaggle/input/kaggle/kaggle.json /root/.kaggle/kaggle.json\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kaggle datasets create -p /kaggle/working/kaggle-dataset --public\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import mixed_precision\nimport datetime\n\n# ====================================\n# 1) Mixed Precision & Basic Setup\n# ====================================\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled:\", mixed_precision.global_policy())\n\n# ====================================\n# 2) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/updatev5/latest_model1.keras\"  # Update this manually after re-upload\nlatest_model_path = os.path.join(save_dir, \"latest_model1.keras\")  # Won't be used after session ends\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64  # Optimized for Kaggle\ninput_shape = (224, 224, 3)\ninitial_learning_rate = 5e-4  # Higher LR for base training\nfine_tune_learning_rate = 5e-6  # Lower LR for fine-tuning\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.convnext import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=30,  # Reduced from 40\n    width_shift_range=0.15,  # Reduced from 0.2\n    height_shift_range=0.15,\n    shear_range=0.15,  # Reduced from 0.2\n    zoom_range=0.2,  # Reduced from 0.3\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],  # Less aggressive\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE CONVNEXT-TINY MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.ConvNeXtTiny(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 300  # Unfreezing last 300 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax', dtype='float32')\n    ])\n\n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)  # Load from uploaded path, NOT latest_model_path\n    print(\"✅ Loaded latest model from uploaded file. Starting fine-tuning...\")\nelse:\n    print(\"🚀 Starting from scratch with ConvNeXt-Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(latest_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n\n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n\n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(latest_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n\n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE (3 EPOCHS) - YOU WILL COMMENT THIS OUT LATER\n# ====================================\nprint(\"\\n=== Initial Training Phase (ConvNeXt-Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=3, start_epoch=1)\n\n# ====================================\n# 9) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\n# 👉 AFTER RE-UPLOADING THE MODEL, COMMENT OUT THE INITIAL TRAINING SECTION ABOVE\n# 👉 THEN RUN ONLY THIS SECTION\n\nprint(\"\\n=== Fine-Tuning Phase ===\")\nfine_tune_model = create_model(fine_tune=True)  # Reload with more trainable layers\nfine_tune_model.load_weights(uploaded_model_path)  # Load from uploaded path, NOT latest_model_path\ntrain_model_func(fine_tune_model, epochs=4, start_epoch=20)  # Fine-tune for 7 more epochs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (240, 240, 3)  # EfficientNetB1 prefers 240x240\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE EfficientNetB1 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB1(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB1!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB1) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n\n# ====================================\n# 8) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\n\n# print(\"\\n=== Fine-Tuning Phase ===\")\n# fine_tune_model = create_model(fine_tune=True)\n# fine_tune_model.load_weights(uploaded_model_path)\n# train_model_func(fine_tune_model, epochs=4, start_epoch=4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import json\n# import numpy as np\n# import tensorflow as tf\n# from tensorflow.keras.applications.efficientnet import preprocess_input\n# from tensorflow.keras.preprocessing import image\n# from tensorflow.keras.models import load_model\n# import matplotlib.pyplot as plt\n# from tkinter import Tk, filedialog\n\n# # ==============================\n# # 1) Load Model and Class Indices\n# # ==============================\n# model_path = \"/kaggle/input/flowers6testing/latest_model.keras\"  # Update as needed\n# class_indices_path = \"/kaggle/input/flowers6testing/class_indices (11).json\"\n\n# model = load_model(model_path)\n# with open(class_indices_path, 'r') as f:\n#     class_indices = json.load(f)\n# inv_class_indices = {v: k for k, v in class_indices.items()}\n\n# # ==============================\n# # 2) Select Image from PC\n# # ==============================\n# def select_image():\n#     root = Tk()\n#     root.withdraw()  # Hide the main window\n#     file_path = filedialog.askopenfilename(title=\"Select Image\", filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n#     return file_path\n\n# image_path = select_image()\n\n# # ==============================\n# # 3) Preprocess Image for Prediction\n# # ==============================\n# def preprocess_img(img_path):\n#     img = image.load_img(img_path, target_size=(240, 240))\n#     img_array = image.img_to_array(img)\n#     img_array = np.expand_dims(img_array, axis=0)\n#     return preprocess_input(img_array)\n\n# img_array = preprocess_img(image_path)\n\n# # ==============================\n# # 4) Prediction & Display\n# # ==============================\n# preds = model.predict(img_array)\n# pred_class = np.argmax(preds[0])\n# predicted_label = inv_class_indices[pred_class]\n\n# # Display Results\n# plt.imshow(image.load_img(image_path))\n# plt.axis('off')\n# plt.title(f\"Predicted: {predicted_label}\")\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nimport json\nimport os\n\n# Paths\nuploaded_model_path = \"/kaggle/input/flowers6testing/latest_model.keras\"  # Update if needed\nclass_indices_path = \"/kaggle/input/flowers6testing/class_indices (11).json\"   # Update if needed\nimage_path = \"/kaggle/input/cath-tset/cath5.png\"  # Change this after uploading your image\n\n# Load class indices\nwith open(class_indices_path, \"r\") as f:\n    class_indices = json.load(f)\nclass_labels = {v: k for k, v in class_indices.items()}\n\n# Load model\nmodel = tf.keras.models.load_model(uploaded_model_path)\n\n# Load and preprocess image\ndef preprocess_image(image_path, target_size=(240, 240)):\n    img = image.load_img(image_path, target_size=target_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    return preprocess_input(img_array)\n\n# Prediction\nimg_array = preprocess_image(image_path)\nprediction = model.predict(img_array)\npredicted_class = class_labels[np.argmax(prediction)]\n\nprint(f\"✅ Predicted Class: {predicted_class}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (256, 256, 3)  # Swin Transformer Tiny expects 256x256\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.swin_transformer import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE Swin Transformer Tiny MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.SwinTransformerTiny(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreezing last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with Swin Transformer Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (Swin Transformer Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n\n# ====================================\n# 8) FINE-TUNING PHASE (OPTIONAL)\n# ====================================\n\n# print(\"\\n=== Fine-Tuning Phase ===\")\n# fine_tune_model = create_model(fine_tune=True)\n# fine_tune_model.load_weights(uploaded_model_path)\n# train_model_func(fine_tune_model, epochs=4, start_epoch=4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install keras-cv\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install timm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras_cv\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  \nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  \ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # Swin Transformer prefers 224x224\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\ndatagen = ImageDataGenerator(\n    preprocessing_function=None,  # Swin Transformer does not require a built-in preprocessing function\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE SWIN TRANSFORMER MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras_cv.models.SwinTransformerTiny(\n        include_top=False,\n        input_shape=input_shape,\n        pretrained=True\n    )\n\n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 50  # Unfreezing last 50 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n\n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with Swin Transformer!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (Swin Transformer Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:37:13.117538Z","iopub.execute_input":"2025-03-10T10:37:13.117824Z","iopub.status.idle":"2025-03-10T10:37:37.077109Z","shell.execute_reply.started":"2025-03-10T10:37:13.117803Z","shell.execute_reply":"2025-03-10T10:37:37.075769Z"}},"outputs":[{"name":"stdout","text":"Class indices: {'Azadirachta_indica': 0, 'Betula_pendula': 1, 'Camphora_officinarum': 2, 'Ceiba_pentandra': 3, 'Eucalyptus_globulus': 4, 'Ligustrum_lucidum': 5, 'Paulownia_tomentosa': 6, 'Pinus_halepensis': 7, 'Spathodea_campanulata': 8, 'Washingtonia_robusta': 9}\nFound 38989 images belonging to 10 classes.\nFound 9741 images belonging to 10 classes.\n🚀 Training from scratch with Swin Transformer!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a178ff85c30b>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 Training from scratch with Swin Transformer!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mfine_tune_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m# ====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-a178ff85c30b>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(fine_tune)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m# ====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     base_model = keras_cv.models.SwinTransformerTiny(\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras_cv.api.models' has no attribute 'SwinTransformerTiny'"],"ename":"AttributeError","evalue":"module 'keras_cv.api.models' has no attribute 'SwinTransformerTiny'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport timm\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\n\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/trees-nineteen-dataset\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # Swin Transformer prefers 224x224\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\n\n\n# datagen = ImageDataGenerator(\n#     preprocessing_function=preprocess_input,\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.25,\n#     horizontal_flip=True,\n#     brightness_range=[0.7, 1.3],\n#     fill_mode=\"nearest\",\n#     validation_split=0.2\n# )\ndatagen = ImageDataGenerator(\n    preprocessing_function=lambda x: (x / 255.0 - 0.5) * 2,  # Normalize between -1 and 1\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE Swin Transformer Tiny MODEL\n# ====================================\n# def create_model(fine_tune=False):\n#     base_model = keras.applications.SwinTransformerTiny(\n#         include_top=False,\n#         weights=\"imagenet\",\n#         input_shape=input_shape\n#     )\n    \n#     if fine_tune:\n#         base_model.trainable = True\n#         fine_tune_at = len(base_model.layers) - 50  # Unfreezing last 50 layers\n#         for layer in base_model.layers[:fine_tune_at]:\n#             layer.trainable = False\n#         learning_rate = fine_tune_learning_rate\n#     else:\n#         base_model.trainable = False\n#         learning_rate = initial_learning_rate\n    \n#     model = keras.Sequential([\n#         keras.Input(shape=input_shape),\n#         base_model,\n#         layers.GlobalAveragePooling2D(),\n#         layers.BatchNormalization(),\n#         layers.Dense(512, activation='relu'),\n#         layers.Dropout(0.5),\n#         layers.Dense(num_classes, activation='softmax')\n#     ])\n    \n#     optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n#     model.compile(\n#         optimizer=optimizer,\n#         loss='categorical_crossentropy',\n#         metrics=['accuracy']\n#     )\n#     return model\ndef create_model(fine_tune=False):\n    base_model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=0)\n    base_model.trainable = fine_tune  # Freeze if fine_tune=False\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        layers.Lambda(lambda x: tf.image.resize(x, (224, 224))),  # Resize for Swin Transformer\n        base_model,\n        layers.GlobalAveragePooling2D(),\n\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=fine_tune_learning_rate if fine_tune else initial_learning_rate)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with Swin Transformer Tiny!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (Swin Transformer Tiny) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:44:47.626599Z","iopub.execute_input":"2025-03-10T10:44:47.626946Z","iopub.status.idle":"2025-03-10T10:45:03.719401Z","shell.execute_reply.started":"2025-03-10T10:44:47.626917Z","shell.execute_reply":"2025-03-10T10:45:03.717993Z"}},"outputs":[{"name":"stdout","text":"Class indices: {'Azadirachta_indica': 0, 'Betula_pendula': 1, 'Camphora_officinarum': 2, 'Ceiba_pentandra': 3, 'Eucalyptus_globulus': 4, 'Ligustrum_lucidum': 5, 'Paulownia_tomentosa': 6, 'Pinus_halepensis': 7, 'Spathodea_campanulata': 8, 'Washingtonia_robusta': 9}\nFound 38989 images belonging to 10 classes.\nFound 9741 images belonging to 10 classes.\n🚀 Training from scratch with Swin Transformer Tiny!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7a73b56d9825>\u001b[0m in \u001b[0;36m<cell line: 160>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🚀 Training from scratch with Swin Transformer Tiny!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mfine_tune_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;31m# ====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-7a73b56d9825>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(fine_tune)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tune\u001b[0m  \u001b[0;31m# Freeze if fine_tune=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     model = keras.Sequential([\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Resize for Swin Transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigin_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;34m\"Only instances of `keras.Layer` can be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;34mf\"added to a Sequential model. Received: {layer} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: SwinTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n  )\n  (layers): Sequential(\n    (0): SwinTransformerStage(\n      (downsample): Identity()\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): Identity()\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): Identity()\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.009)\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.009)\n        )\n      )\n    )\n    (1): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=384, out_features=192, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.018)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.018)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.027)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.027)\n        )\n      )\n    )\n    (2): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=768, out_features=384, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.036)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.036)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.045)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.045)\n        )\n        (2): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.055)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.055)\n        )\n        (3): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.064)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.064)\n        )\n        (4): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.073)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.073)\n        )\n        (5): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.082)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.082)\n        )\n      )\n    )\n    (3): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.091)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.091)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.100)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.100)\n        )\n      )\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (head): ClassifierHead(\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n    (drop): Dropout(p=0.0, inplace=False)\n    (fc): Identity()\n    (flatten): Identity()\n  )\n) (of type <class 'timm.models.swin_transformer.SwinTransformer'>)"],"ename":"ValueError","evalue":"Only instances of `keras.Layer` can be added to a Sequential model. Received: SwinTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n  )\n  (layers): Sequential(\n    (0): SwinTransformerStage(\n      (downsample): Identity()\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): Identity()\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): Identity()\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.009)\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.009)\n        )\n      )\n    )\n    (1): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=384, out_features=192, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.018)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.018)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.027)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.027)\n        )\n      )\n    )\n    (2): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=768, out_features=384, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.036)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.036)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.045)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.045)\n        )\n        (2): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.055)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.055)\n        )\n        (3): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.064)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.064)\n        )\n        (4): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.073)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.073)\n        )\n        (5): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.082)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.082)\n        )\n      )\n    )\n    (3): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.091)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.091)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.100)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.100)\n        )\n      )\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (head): ClassifierHead(\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n    (drop): Dropout(p=0.0, inplace=False)\n    (fc): Identity()\n    (flatten): Identity()\n  )\n) (of type <class 'timm.models.swin_transformer.SwinTransformer'>)","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"!pip install timm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:40:26.359400Z","iopub.execute_input":"2025-03-10T10:40:26.359729Z","iopub.status.idle":"2025-03-10T10:40:29.677428Z","shell.execute_reply.started":"2025-03-10T10:40:26.359706Z","shell.execute_reply":"2025-03-10T10:40:29.676548Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.29.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->timm) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->timm) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision->timm) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/flowers-nineteen19\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (300, 300, 3)  # EfficientNetB3 prefers 300x300\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE EfficientNetB3 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB3!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB3) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:48:24.152912Z","iopub.execute_input":"2025-03-10T10:48:24.153287Z","iopub.status.idle":"2025-03-10T10:48:27.577313Z","shell.execute_reply.started":"2025-03-10T10:48:24.153263Z","shell.execute_reply":"2025-03-10T10:48:27.576107Z"}},"outputs":[{"name":"stdout","text":"Class indices: {'Azadirachta_indica': 0, 'Betula_pendula': 1, 'Camphora_officinarum': 2, 'Ceiba_pentandra': 3, 'Eucalyptus_globulus': 4, 'Ligustrum_lucidum': 5, 'Paulownia_tomentosa': 6, 'Pinus_halepensis': 7, 'Spathodea_campanulata': 8, 'Washingtonia_robusta': 9}\nFound 0 images belonging to 10 classes.\nFound 0 images belonging to 10 classes.\n🚀 Training from scratch with EfficientNetB3!\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n\n=== Initial Training Phase (EfficientNetB3) ===\n\n🔄 Training Epoch 1/15...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-648c486f9d40>\u001b[0m in \u001b[0;36m<cell line: 158>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;31m# ====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Initial Training Phase (EfficientNetB3) ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mtrain_model_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tune_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-648c486f9d40>\u001b[0m in \u001b[0;36mtrain_model_func\u001b[0;34m(model, epochs, start_epoch)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mmodel_epoch_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_prefix}{epoch}.keras\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/tree/optree_impl.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`func` must be callable. Received: func={func}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstructures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must provide at least one structure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Must provide at least one structure"],"ename":"ValueError","evalue":"Must provide at least one structure","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport json\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/flowers-nineteen19\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # EfficientNetB3 prefers 300x300\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) FIX DATASET STRUCTURE\n# ====================================\nfor class_name in os.listdir(image_dir):\n    class_path = os.path.join(image_dir, class_name)\n    if os.path.isdir(class_path):\n        subfolders = [f for f in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, f))]\n        for subfolder in subfolders:\n            subfolder_path = os.path.join(class_path, subfolder)\n            for file in os.listdir(subfolder_path):\n                src_path = os.path.join(subfolder_path, file)\n                dst_path = os.path.join(class_path, file)\n                shutil.move(src_path, dst_path)\n            os.rmdir(subfolder_path)\nprint(\"✅ Dataset structure fixed!\")\n\n# ====================================\n# 3) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 4) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 5) DEFINE EfficientNetB3 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 6) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB3!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 7) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 8) INITIAL TRAINING PHASE (15 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB3) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:54:43.160105Z","iopub.execute_input":"2025-03-10T10:54:43.160416Z","iopub.status.idle":"2025-03-10T10:54:55.245867Z","shell.execute_reply.started":"2025-03-10T10:54:43.160389Z","shell.execute_reply":"2025-03-10T10:54:55.244558Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/flowers-nineteen19/Alliaria_petiolata/Alliaria_petiolata/Alliaria petiolata_1985.png' -> '/kaggle/input/flowers-nineteen19/Alliaria_petiolata/Alliaria petiolata_1985.png'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-39a7c5e863c9>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0msrc_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mdst_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Dataset structure fixed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/flowers-nineteen19/Alliaria_petiolata/Alliaria petiolata_1985.png'"],"ename":"OSError","evalue":"[Errno 30] Read-only file system: '/kaggle/input/flowers-nineteen19/Alliaria_petiolata/Alliaria petiolata_1985.png'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport datetime\n\n# ====================================\n# 1) CONFIGURATION & PATHS\n# ====================================\nimage_dir = \"/kaggle/input/flowers-nineteen19\"  # Update this with your dataset path\nsave_dir = \"/kaggle/working\"\nos.makedirs(save_dir, exist_ok=True)\n\nmodel_prefix = os.path.join(save_dir, \"model_epoch_\")\nuploaded_model_path = \"/kaggle/input/latest_flower_model_nineteen/latest_model.keras\"  # Update this manually\ntmp_model_path = os.path.join(save_dir, \"latest_model.keras\")\nhistory_path = os.path.join(save_dir, \"history.json\")\nclass_indices_path = os.path.join(save_dir, \"class_indices.json\")\nlog_dir = os.path.join(save_dir, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\nbatch_size = 64\ninput_shape = (224, 224, 3)  # EfficientNetB3 prefers 300x300\ninitial_learning_rate = 5e-6\nfine_tune_learning_rate = 1e-5\n\n# ====================================\n# 2) DETECT CLASSES & BUILD CLASS INDICES\n# ====================================\ndetected_classes = sorted(d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d)))\n\nif os.path.exists(class_indices_path):\n    with open(class_indices_path, \"r\") as f:\n        class_indices = json.load(f)\nelse:\n    class_indices = {name: i for i, name in enumerate(detected_classes)}\n    with open(class_indices_path, \"w\") as f:\n        json.dump(class_indices, f)\nnum_classes = len(class_indices)\nprint(\"Class indices:\", class_indices)\n\n# ====================================\n# 3) DATA AUGMENTATION & PREPROCESSING\n# ====================================\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    brightness_range=[0.7, 1.3],\n    fill_mode=\"nearest\",\n    validation_split=0.2\n)\n\ntrain_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True,\n    classes=list(class_indices.keys())\n)\n\nval_generator = datagen.flow_from_directory(\n    directory=image_dir,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=list(class_indices.keys())\n)\n\n# ====================================\n# 4) DEFINE EfficientNetB3 MODEL\n# ====================================\ndef create_model(fine_tune=False):\n    base_model = keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n    \n    if fine_tune:\n        base_model.trainable = True\n        fine_tune_at = len(base_model.layers) - 200  # Unfreezing last 200 layers\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        learning_rate = fine_tune_learning_rate\n    else:\n        base_model.trainable = False\n        learning_rate = initial_learning_rate\n    \n    model = keras.Sequential([\n        keras.Input(shape=input_shape),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# ====================================\n# 5) LOAD PREVIOUS MODEL (IF RESUMING)\n# ====================================\nif os.path.exists(uploaded_model_path):\n    fine_tune_model = create_model(fine_tune=True)\n    fine_tune_model.load_weights(uploaded_model_path)\n    print(\"✅ Loaded latest model. Fine-tuning...\")\nelse:\n    print(\"🚀 Training from scratch with EfficientNetB3!\")\n    fine_tune_model = create_model(fine_tune=False)\n\n# ====================================\n# 6) TRAINING FUNCTION WITH CALLBACKS\n# ====================================\ndef train_model_func(model, epochs, start_epoch=1):\n    callbacks = [\n        ModelCheckpoint(tmp_model_path, save_best_only=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        TensorBoard(log_dir=log_dir)\n    ]\n    \n    for epoch in range(start_epoch, start_epoch + epochs):\n        print(f\"\\n🔄 Training Epoch {epoch}/{start_epoch + epochs - 1}...\")\n        model.fit(train_generator, validation_data=val_generator, epochs=1, callbacks=callbacks)\n        \n        model_epoch_path = f\"{model_prefix}{epoch}.keras\"\n        model.save(model_epoch_path)\n        model.save(tmp_model_path)\n        print(f\"✅ Model saved: {model_epoch_path}\")\n    \n    print(\"✅ Training session complete!\")\n\n# ====================================\n# 7) INITIAL TRAINING PHASE (3 EPOCHS)\n# ====================================\nprint(\"\\n=== Initial Training Phase (EfficientNetB3) ===\")\ntrain_model_func(fine_tune_model, epochs=15, start_epoch=1)\n\n# ====================================\n# 8) FINE-TUNING PHASE (AFTER 3 EPOCHS)\n# ====================================\n\n# print(\"\\n=== Fine-Tuning Phase ===\")\n# fine_tune_model = create_model(fine_tune=True)\n# fine_tune_model.load_weights(uploaded_model_path)\n# train_model_func(fine_tune_model, epochs=4, start_epoch=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T11:03:46.087551Z","iopub.execute_input":"2025-03-10T11:03:46.087869Z","execution_failed":"2025-03-10T11:03:49.363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}